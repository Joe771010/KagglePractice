{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  11500 dog train images\n",
      "There are  11500 cat train images\n",
      "There are  1000 dog valid images\n",
      "There are  1000 cat valid images\n"
     ]
    }
   ],
   "source": [
    "# After unzipping training data manually, all 25000 images are in the 'train' folder.\n",
    "# Use the script below to put dog images into 'train/dogs/' and cat images into 'train/cats/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dir_train = 'train'\n",
    "dir_train_dogs = 'train/dogs'\n",
    "dir_train_cats = 'train/cats'\n",
    "\n",
    "dir_valid = 'valid'\n",
    "dir_valid_dogs = 'valid/dogs'\n",
    "dir_valid_cats = 'valid/cats'\n",
    "\n",
    "if not os.path.exists(dir_train_dogs):\n",
    "    os.mkdir(dir_train_dogs)\n",
    "    \n",
    "if not os.path.exists(dir_train_cats):\n",
    "    os.mkdir(dir_train_cats)\n",
    "    \n",
    "if not os.path.exists(dir_valid_dogs):\n",
    "    os.mkdir(dir_valid_dogs)\n",
    "    \n",
    "if not os.path.exists(dir_valid_cats):\n",
    "    os.mkdir(dir_valid_cats)\n",
    "\n",
    "# Initially all images are put in 'train'\n",
    "# separate dogs and cats in train/dogs and train/cats\n",
    "[os.rename(os.path.join(dir_train, f), os.path.join(dir_train_dogs, f)) for f in os.listdir(dir_train) if 'dog.' in f]\n",
    "[os.rename(os.path.join(dir_train, f), os.path.join(dir_train_cats, f)) for f in os.listdir(dir_train) if 'cat.' in f]\n",
    "\n",
    "# put all images in valid folder back to train folder\n",
    "[os.rename(os.path.join(dir_valid_dogs, f), os.path.join(dir_train_dogs, f)) for f in os.listdir(dir_valid_dogs)]\n",
    "[os.rename(os.path.join(dir_valid_cats, f), os.path.join(dir_train_cats, f)) for f in os.listdir(dir_valid_cats)]\n",
    "\n",
    "# select 1000 images for validation repectively\n",
    "[os.rename(os.path.join(dir_train_dogs, f), os.path.join(dir_valid_dogs, f)) for f in np.random.choice(os.listdir(dir_train_dogs), 1000, replace=False)]\n",
    "[os.rename(os.path.join(dir_train_cats, f), os.path.join(dir_valid_cats, f)) for f in np.random.choice(os.listdir(dir_train_cats), 1000, replace=False)]\n",
    "\n",
    "print('There are ', len(os.listdir(dir_train_dogs)), 'dog train images')\n",
    "print('There are ', len(os.listdir(dir_train_cats)), 'cat train images')\n",
    "print('There are ', len(os.listdir(dir_valid_dogs)), 'dog valid images')\n",
    "print('There are ', len(os.listdir(dir_valid_cats)), 'cat valid images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Declare the ImageDataGenerator of Keras\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "train_datagen = ImageDataGenerator(    \n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.05,\n",
    "    fill_mode=\"constant\",\n",
    "    channel_shift_range=10,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_train, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16, \n",
    "    class_mode='categorical', \n",
    "    shuffle=True) \n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    dir_valid, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16, \n",
    "    class_mode='categorical', \n",
    "    shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly load 200 images for normalization\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# X_train = []\n",
    "# for f in np.random.choice(os.listdir(dir_train_dogs), 100, replace=False):\n",
    "#     X_train.append(cv2.resize(cv2.imread(os.path.join(dir_train_dogs, f)), (224, 224)))\n",
    "# for f in np.random.choice(os.listdir(dir_train_cats), 100, replace=False):\n",
    "#     X_train.append(cv2.resize(cv2.imread(os.path.join(dir_train_cats, f)), (224, 224)))\n",
    "\n",
    "# X_train = np.stack(X_train)\n",
    "\n",
    "# # train_datagen.fit() outputs strange mean and std ...\n",
    "# # manually calculate and set\n",
    "# train_datagen.mean = np.mean(X_train, axis=(0,1,2))\n",
    "# train_datagen.std = np.std(X_train, axis=(0,1,2))\n",
    "\n",
    "# print('normalization mean:', train_datagen.mean)\n",
    "# print('normalization std:', train_datagen.std)\n",
    "\n",
    "# del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model contains 177 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvbridgechiao/kaggle/dogs_vs_cats/venv/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained cnn model: \n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, Activation, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = (224, 224, 3),\n",
    "    pooling = 'None')\n",
    "\n",
    "# Add a layer for two-class classification\n",
    "last_layer = base_model.output\n",
    "# last_layer = BatchNormalization(axis=3)(last_layer)\n",
    "last_layer = GlobalAveragePooling2D()(last_layer)\n",
    "last_layer = Dense(2, activation='softmax')(last_layer)\n",
    "\n",
    "# Do not train original parameters\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model.layers[-1].tranable = True\n",
    "base_model.layers[-2].tranable = True\n",
    "base_model.layers[-3].tranable = True\n",
    "base_model.layers[-4].tranable = True\n",
    "\n",
    "model = Model(input=base_model.input, output=last_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# del base_model\n",
    "\n",
    "print('model contains', len(model.layers), 'layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Activation object at 0x7f2ba84109e8>\n",
      "<keras.layers.merge.Add object at 0x7f2ba84829b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f2ba84b2080>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f2ba84953c8>\n",
      "-1\n",
      "-2\n",
      "-3\n",
      "-4\n"
     ]
    }
   ],
   "source": [
    "# print(model.summary())\n",
    "# print(base_model.layers[-1])\n",
    "# print(base_model.layers[-2])\n",
    "# print(base_model.layers[-3])\n",
    "# print(base_model.layers[-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 0.1169 - acc: 0.9544 - val_loss: 0.0680 - val_acc: 0.9812\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 0.1475 - acc: 0.9494 - val_loss: 0.1521 - val_acc: 0.9625\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 35s 353ms/step - loss: 0.1163 - acc: 0.9581 - val_loss: 0.3408 - val_acc: 0.9313\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 36s 363ms/step - loss: 0.1068 - acc: 0.9619 - val_loss: 0.0689 - val_acc: 0.9688\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.1272 - acc: 0.9537 - val_loss: 0.1432 - val_acc: 0.9750\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 36s 355ms/step - loss: 0.1002 - acc: 0.9650 - val_loss: 0.0868 - val_acc: 0.9563\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.0786 - acc: 0.9694 - val_loss: 0.2089 - val_acc: 0.9625\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.0921 - acc: 0.9631 - val_loss: 0.2684 - val_acc: 0.9375\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.0941 - acc: 0.9619 - val_loss: 0.1224 - val_acc: 0.9500\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.0853 - acc: 0.9706 - val_loss: 0.0621 - val_acc: 0.9875\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.0862 - acc: 0.9681 - val_loss: 0.0942 - val_acc: 0.9688\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 0.0865 - acc: 0.9681 - val_loss: 0.1090 - val_acc: 0.9500\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 35s 355ms/step - loss: 0.1139 - acc: 0.9562 - val_loss: 0.2116 - val_acc: 0.9625\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.0868 - acc: 0.9669 - val_loss: 0.0893 - val_acc: 0.9750\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.1204 - acc: 0.9581 - val_loss: 0.0128 - val_acc: 0.9938\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.0905 - acc: 0.9669 - val_loss: 0.0582 - val_acc: 0.9875\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 0.0798 - acc: 0.9669 - val_loss: 0.1102 - val_acc: 0.9625\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 0.1044 - acc: 0.9594 - val_loss: 0.0635 - val_acc: 0.9688\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 0.0954 - acc: 0.9587 - val_loss: 0.1590 - val_acc: 0.9750\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 0.1023 - acc: 0.9619 - val_loss: 0.1046 - val_acc: 0.9750\n",
      "CPU times: user 13min 56s, sys: 12.8 s, total: 14min 9s\n",
      "Wall time: 11min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training process\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=20, steps_per_epoch=100, validation_data=valid_generator, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f5656163a5a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'lr'"
     ]
    }
   ],
   "source": [
    "# change learning rate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.lr.set_value(0.00005)\n",
    "history = model.fit_generator(train_generator, epochs=10, steps_per_epoch=100, validation_data=valid_generator, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all layers to trainable\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# adam = Adam(lr=0.00005)\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])    \n",
    "# print(model.summary())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training process\n",
    "\n",
    "# history = model.fit_generator(train_generator, epochs=5, steps_per_epoch=200, validation_data=valid_generator, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation acc: 0.9713541666666666\n",
      "validation loss: 0.11058699955631254\n"
     ]
    }
   ],
   "source": [
    "valid_acc = 0\n",
    "valid_loss = 0\n",
    "for i in range(120):\n",
    "    (x, y) = valid_generator.next()\n",
    "    valid_loss += model.evaluate(x, y, verbose=0)[0]\n",
    "    valid_acc += model.evaluate(x, y, verbose=0)[1]\n",
    "print('validation acc:', valid_acc/120)\n",
    "print('validation loss:', valid_loss/120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_0212_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
